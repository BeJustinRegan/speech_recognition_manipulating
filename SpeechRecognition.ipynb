{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eol1fSATlkfa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s3obGhGjl28o",
        "outputId": "449112f4-11ce-4040-926d-1730eb8e668e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data/mini_speech_commands.zip'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.get_file(\n",
        "    origin = \"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "    extract = True,\n",
        "    cache_dir = '.',\n",
        "    cache_subdir = 'data'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UL42p8fxnoEK"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"data/mini_speech_commands/\"\n",
        "data_dir = pathlib.Path(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khs8yxfinAf7",
        "outputId": "ae242cba-3d5d-492f-b27b-fbfe0544bb9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 8 classes.\n",
            "Using 5600 files for training.\n",
            "Using 2400 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    # directory data\n",
        "    directory = data_dir,\n",
        "    # jumlah sample dalam satu batch\n",
        "    batch_size = 64,\n",
        "    # train 70%, validation 30%\\\n",
        "    validation_split = 0.3,\n",
        "    seed = 0,\n",
        "    output_sequence_length = 16000,\n",
        "    subset = 'both'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-u1OVSVoM3x",
        "outputId": "de0fecd6-7964-46f6-b0bf-bb199b665f0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n"
          ]
        }
      ],
      "source": [
        "# datain dari dataset kita ada label namesnya apa aja\n",
        "label_names = np.array(train_ds.class_names)\n",
        "print(label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWBtBJBeotKA"
      },
      "outputs": [],
      "source": [
        "# squeeze -> untk hilangin axis terakhir utk jadiin dia mono audio\n",
        "# (num samples, num_channels) -> (num_samples,)\n",
        "\n",
        "def squeeze(audio, label):\n",
        "  audio = tf.squeeze(audio, axis = -1)\n",
        "  return audio, label\n",
        "\n",
        "# autotune -> kontrol berapa banyak calls yang bisa dijalankan secara pararel atau bersamaan berdasarkan resource yang ada\n",
        "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROkPrhBZprMw"
      },
      "outputs": [],
      "source": [
        "# split validation using shard\n",
        "# awalnya dataset validation = 30%, tapi soal mintanya 15% val, 15% test\n",
        "\n",
        "test_ds = val_ds.shard(num_shards = 2, index = 0)\n",
        "val = val_ds.shard(num_shards = 2, index = 1)\n",
        "# val ds akan kepecah menjadi 2, test ds ambil yang 50% pertama dari 30% = 15%\n",
        "# val ds ambil 50% kedua dari 30% = 15%\n",
        "\n",
        "# training = 70%, val = 15%, test = 15%\n",
        "# data sekarang training = 70%, val = 15%, test 15%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmaqrLMzrqNW"
      },
      "outputs": [],
      "source": [
        "# bikin spectogram dari waveform\n",
        "def get_spectogram(waveform):\n",
        "  # STFT -> Short Time Fourier Transform\n",
        "  spectogram = tf.signal.stft(\n",
        "      waveform,\n",
        "      frame_length = 255,\n",
        "      frame_step = 128\n",
        "  )\n",
        "\n",
        "  # ambil magnitudenya\n",
        "  spectogram = tf.abs(spectogram)\n",
        "  # perlu tambahin satu axis/dimensi, supaya bisa di feed ke model kita (CNN)\n",
        "  spectogram = spectogram[..., tf.newaxis]\n",
        "  return spectogram\n",
        "\n",
        "# function tambahan untuk mempermudah apply/call function spectogram\n",
        "\n",
        "def make_spec_ds(ds):\n",
        "  return ds.map(\n",
        "      # aplikasiin lambda function utk panggil si get_spectogram\n",
        "      map_func = lambda audio, label: (get_spectogram(audio), label),num_parallel_calls = tf.data.AUTOTUNE\n",
        "  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzpZv2JxtKc4"
      },
      "outputs": [],
      "source": [
        "train_spectogram_ds = make_spec_ds(train_ds)\n",
        "val_spectogram_ds = make_spec_ds(val_ds)\n",
        "test_spectogram_ds = make_spec_ds(test_ds)\n",
        "\n",
        "# optimization (cache & AUTOTUNE) dan shuffle\n",
        "train_spectogram_ds = train_spectogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "val_spectogram_ds = val_spectogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_spectogram_ds = test_spectogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4naYoLZvk3C"
      },
      "outputs": [],
      "source": [
        "# ambil salah satu batch data\n",
        "\n",
        "for example_sc, example_sc_lbl in train_spectogram_ds.take(1):\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2aYJZS6uJfH",
        "outputId": "65a22463-b1c6-418b-b5ac-f3bcabef4af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing_3 (Resizing)       (None, 32, 32, 1)         0         \n",
            "                                                                 \n",
            " normalization_3 (Normaliza  (None, 32, 32, 1)         3         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1625611 (6.20 MB)\n",
            "Trainable params: 1625608 (6.20 MB)\n",
            "Non-trainable params: 3 (16.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# architecture CNN\n",
        "# input layer -> entry pointdata kedalam model (termasuk preprocess data sebelum dilanjutin ke hidden layer)\n",
        "\n",
        "# hidden layer -> inti dari model, resize, convolution layer, maxpooling\n",
        "\n",
        "# output layer -> dense layer/fully connected layer, ini perlu disesuaikan sama banyaknya label /jenis output\n",
        "\n",
        "input_shape = example_sc.shape[1:]\n",
        "\n",
        "norm_layer = layers.Normalization()\n",
        "# dipasangin lambda function krn hanya butuh spectogramnya saja, tidak perlu semuanya\n",
        "norm_layer.adapt(data = train_spectogram_ds.map(map_func = lambda spec, label: spec))\n",
        "\n",
        "model = models.Sequential([\n",
        "    # input layer\n",
        "    layers.Input(shape = input_shape),\n",
        "    # resize layer -> utk ngeresize spectogram supaya seragam\n",
        "    layers.Resizing(32, 32),\n",
        "    # normalization layer -> supaya data berada dalam satu range yang sama semua\n",
        "    norm_layer,\n",
        "\n",
        "    # hidden layer -> maxpooling, dropout, convolution\n",
        "    # 32 filter, 3x3 size filter\n",
        "    # menghasilkan 32 basic pattern dari setiap spectogram\n",
        "    layers.Conv2D(32, 3, activation = 'relu'),\n",
        "    layers.Conv2D(64, 3, activation = 'relu'),\n",
        "\n",
        "    # maxpooling -> utk extract fitur/pattern yang dominan -> tuk prevent overfitting\n",
        "    layers.MaxPooling2D(),\n",
        "    # droupout -> randomly ngedrop data supaya ngeprevent modelnya overfitting\n",
        "    layers.Dropout(0.2),\n",
        "    # o.2 = 20%\n",
        "\n",
        "    # overfitting = modelnya terlalu smart dalam mengingat hal yang sudah di train, sehingga menyebabkan kaku, jadi sulit recognize hal yang baru-> biasanya terjadi karena model terlalu complex\n",
        "\n",
        "    # underfitting = simply kurang pinter modelnya\n",
        "\n",
        "    # flatten layer\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # dense layer\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.1),\n",
        "\n",
        "    # output layer -> sesuain sama jumlah label kalian\n",
        "    layers.Dense(len(label_names))\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
